# ğŸŒ Idiomas Disponibles

ğŸ‡¬ğŸ‡§ [InglÃ©s](README.md) | ğŸ‡¨ğŸ‡³ [Chino](README_ZH.md) | ğŸ‡ªğŸ‡¸ [EspaÃ±ol](README_ES.md) | ğŸ‡©ğŸ‡ª [AlemÃ¡n](README_DE.md) | ğŸ‡«ğŸ‡· [FrancÃ©s](README_FR.md) | ğŸ‡®ğŸ‡¹ [Italiano](README_IT.md) | ğŸ‡µğŸ‡¹ [PortuguÃ©s](README_PT.md) | ğŸ‡·ğŸ‡º [Ruso](README_RU.md) | ğŸ‡°ğŸ‡· [Coreano](README_KO.md) | ğŸ‡¯ğŸ‡µ [JaponÃ©s](README_JA.md)

---
# ğŸ§  Whisper Reconocimiento de Voz a Texto (Offline)

Un script en Python para el **reconocimiento automÃ¡tico de voz a partir de archivos de audio** usando el modelo [Whisper](https://github.com/openai/whisper).  
DespuÃ©s de la descarga e instalaciÃ³n, la transcripciÃ³n se realiza **localmente** en tu ordenador sin enviar datos a ningÃºn servidor.

- Reconoce voz en mÃ¡s de 100 idiomas.  
  Para listar los idiomas, ejecuta el script con --help.
- El idioma de la interfaz se puede seleccionar con --ui-lang.  
  Ejecuta el script sin parÃ¡metros para ver las opciones disponibles.
- Modelos soportados: tiny, base, small, medium, large.  
  Cuanto mÃ¡s "grande" sea el modelo, mayores serÃ¡n los requisitos de recursos y mejor la precisiÃ³n.  
  Si no se proporciona --model, el script selecciona automÃ¡ticamente un modelo en funciÃ³n de la RAM disponible.
- Proporciona un archivo de audio con --file. Formatos soportados: .wav, .mp3, .m4a, .ogg, etc.  
- Muestra una vista previa corta y guarda el texto completo en output.txt.

**âš  Importante:**  
En el primer uso de un modelo Whisper seleccionado, se descargarÃ¡ **automÃ¡ticamente de internet**.  
El tamaÃ±o de los modelos es grande: desde ~150MB (tiny) hasta ~3GB (large). AsegÃºrate de tener una conexiÃ³n estable y suficiente espacio en disco.

---

## ğŸ–¥ï¸ Requisitos del Sistema
- SO: Windows 10/11, Ubuntu 20.04+, macOS 11+  
- RAM: mÃ­nimo 4GB (16GB recomendados para large)  
- Espacio en disco: ~6GB libres  
- CPU: x86_64 con soporte AVX (recomendado)

ğŸ“¦ Una vez descargado, el modelo funciona completamente offline.

## âœ… Requisitos
- **Python** 3.10  
- **ffmpeg** (decodificaciÃ³n de audio)  
- **git** (clonado del repositorio)

---

## âš™ï¸ InstalaciÃ³n

### ğŸªŸ Windows

1. Instalar [Python 3.10](https://www.python.org/downloads/)

2. Instalar **Git** (https://git-scm.com/download/win) â€” elegir *"Git from the command line"* durante la instalaciÃ³n.

3. Instalar **ffmpeg**: descargar desde https://ffmpeg.org/download.html, descomprimir y aÃ±adir `bin/` al `PATH` (o colocar ffmpeg.exe junto al script).

4. Clonar el repositorio:
```bash
git clone https://github.com/avkarcr/audio2text.git
cd audio2text
```

5. Crear y activar un entorno virtual:
```bash
python -m venv venv
venv\Scripts\activate
```

6. Instalar dependencias:
```bash
pip install -r requirements.txt
```

---

### ğŸ§ Linux (Ubuntu/Debian)

1. Instalar **Python 3.10+**. En Ubuntu 22.04+ viene preinstalado:
```bash
python3 --version
```

2. Instalar **git** y **ffmpeg**:
```bash
sudo apt update
sudo apt install git ffmpeg
```

3. Clonar el repositorio:
```bash
git clone https://github.com/avkarcr/audio2text.git
cd audio2text
```

4. Crear y activar un entorno virtual:
```bash
python3 -m venv venv
source venv/bin/activate
```

5. Instalar dependencias:
```bash
pip install -r requirements.txt
```

---

## ğŸš€ Uso

1. Coloca audio.mp3 en la carpeta data/.  
2. Ejecuta:
```bash
python main.py
```

ğŸ“¦ El modelo y el archivo se seleccionarÃ¡n automÃ¡ticamente.  
En la primera ejecuciÃ³n de un modelo, se descargarÃ¡ automÃ¡ticamente.

---

## ğŸ’¡ Ejemplos

Ejecutar con el modelo medium en inglÃ©s (predeterminado) con interfaz en inglÃ©s (predeterminado):
```bash
python main.py --quiet --file data/audio.mp3 --model medium
```

Ejecutar con audio en coreano e interfaz en coreano:
```bash
python main.py --quiet --file data/audio.mp3 --model medium --lang ko --ui-lang ko
```
---

## ğŸ“„ Salida

ğŸ“ Vista previa del texto reconocido, transcripciÃ³n completa guardada en output.txt.

---

## âš  Notas
- El modelo large requiere 16+GB de RAM.  
- Para audio largo, se recomienda al menos el modelo medium (o dividir el archivo con ffmpeg).

---

## ğŸ“š Licencia
MIT. Utiliza componentes de [Whisper](https://github.com/openai/whisper) de OpenAI.