# ğŸŒ Langues disponibles

ğŸ‡¬ğŸ‡§ [Anglais](README.md) | ğŸ‡¨ğŸ‡³ [Chinois](README_ZH.md) | ğŸ‡ªğŸ‡¸ [Espagnol](README_ES.md) | ğŸ‡©ğŸ‡ª [Allemand](README_DE.md) | ğŸ‡«ğŸ‡· [FranÃ§ais](README_FR.md) | ğŸ‡®ğŸ‡¹ [Italien](README_IT.md) | ğŸ‡µğŸ‡¹ [Portugais](README_PT.md) | ğŸ‡·ğŸ‡º [Russe](README_RU.md) | ğŸ‡°ğŸ‡· [CorÃ©en](README_KO.md) | ğŸ‡¯ğŸ‡µ [Japonais](README_JA.md)

---
# ğŸ§  Whisper Speech-to-Text (Hors ligne)

Un script Python pour la **reconnaissance vocale automatique Ã  partir de fichiers audio** utilisant le modÃ¨le [Whisper](https://github.com/openai/whisper).  
AprÃ¨s tÃ©lÃ©chargement et configuration, la transcription est effectuÃ©e **localement** sur votre ordinateur sans envoyer de donnÃ©es Ã  un serveur.

- ReconnaÃ®t la parole dans plus de 100 langues.  
  Pour lister les langues, exÃ©cutez le script avec lâ€™option --help.
- La langue de lâ€™interface peut Ãªtre sÃ©lectionnÃ©e via --ui-lang.  
  ExÃ©cutez le script sans paramÃ¨tres pour voir les options disponibles.
- ModÃ¨les pris en charge : tiny, base, small, medium, large.  
  Plus le modÃ¨le est "grand", plus il est exigeant en ressources â€” et meilleure est la prÃ©cision.  
  Si lâ€™option --model nâ€™est pas fournie, le script sÃ©lectionne automatiquement un modÃ¨le en fonction de la RAM disponible.
- Fournissez un fichier audio via --file. Formats pris en charge : .wav, .mp3, .m4a, .ogg, etc.  
- Affiche un aperÃ§u court et enregistre le texte complet dans output.txt.

**âš  Important :**  
Lors de la premiÃ¨re utilisation dâ€™un modÃ¨le Whisper sÃ©lectionnÃ©, il sera **tÃ©lÃ©chargÃ© automatiquement depuis Internet**.  
La taille des modÃ¨les est importante â€” dâ€™environ 150 Mo (tiny) Ã  environ 3 Go (large). Assurez-vous dâ€™avoir une connexion stable et suffisamment dâ€™espace disque.

---

## ğŸ–¥ï¸ Configuration systÃ¨me requise
- OS : Windows 10/11, Ubuntu 20.04+, macOS 11+  
- RAM : minimum 4 Go (16 Go recommandÃ©s pour large)  
- Espace disque : ~6 Go libres  
- CPU : x86_64 avec support AVX (recommandÃ©)

ğŸ“¦ AprÃ¨s le premier tÃ©lÃ©chargement, le modÃ¨le fonctionne entiÃ¨rement hors ligne.

## âœ… PrÃ©requis
- **Python** 3.10  
- **ffmpeg** (dÃ©codage audio)  
- **git** (clonage du dÃ©pÃ´t)

---

## âš™ï¸ Installation

### ğŸªŸ Windows

1. Installer [Python 3.10](https://www.python.org/downloads/)

2. Installer **Git** (https://git-scm.com/download/win) â€” choisissez â€œGit from the command lineâ€ pendant lâ€™installation.

3. Installer **ffmpeg** : tÃ©lÃ©chargez depuis https://ffmpeg.org/download.html, dÃ©compressez et ajoutez `bin/` au `PATH` (ou placez `ffmpeg.exe` Ã  cÃ´tÃ© du script).

4. Cloner le dÃ©pÃ´t :
```bash
git clone https://github.com/avkarcr/audio2text.git
cd audio2text
```

5. CrÃ©er et activer un environnement virtuel :
```bash
python -m venv venv
venv\Scripts\activate
```

6. Installer les dÃ©pendances :
```bash
pip install -r requirements.txt
```

---

### ğŸ§ Linux (Ubuntu/Debian)

1. Installer **Python 3.10+**. Sur Ubuntu 22.04+ il est dÃ©jÃ  installÃ© :
```bash
python3 --version
```

2. Installer **git** et **ffmpeg** :
```bash
sudo apt update
sudo apt install git ffmpeg
```

3. Cloner le dÃ©pÃ´t :
```bash
git clone https://github.com/avkarcr/audio2text.git
cd audio2text
```

4. CrÃ©er et activer un environnement virtuel :
```bash
python3 -m venv venv
source venv/bin/activate
```

5. Installer les dÃ©pendances :
```bash
pip install -r requirements.txt
```

---

## ğŸš€ Utilisation

1. Mettre `audio.mp3` dans le dossier `data/`.  
2. Lancer :
```bash
python main.py
```

ğŸ“¦ Le modÃ¨le et le fichier seront sÃ©lectionnÃ©s automatiquement.  
Lors de la premiÃ¨re utilisation, le modÃ¨le sera tÃ©lÃ©chargÃ© automatiquement.

---

## ğŸ’¡ Exemples

ExÃ©cuter avec le modÃ¨le medium en anglais (par dÃ©faut) et interface en anglais (par dÃ©faut) :
```bash
python main.py --quiet --file data/audio.mp3 --model medium
```
ExÃ©cuter avec un audio corÃ©en et interface en corÃ©en :
```bash
python main.py --quiet --file data/audio.mp3 --model medium --lang ko --ui-lang ko
```

---

## ğŸ“„ RÃ©sultat

ğŸ“ AperÃ§u du texte reconnu, transcription complÃ¨te enregistrÃ©e dans `output.txt`.

---

## âš  Remarques
- Le modÃ¨le large nÃ©cessite 16+ Go de RAM.  
- Pour les fichiers audio longs, privilÃ©giez au moins le modÃ¨le medium (ou dÃ©coupez le fichier avec ffmpeg).

---

## ğŸ“š Licence
MIT. Utilise des composants de [Whisper](https://github.com/openai/whisper) dâ€™OpenAI.
