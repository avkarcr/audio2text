# ğŸŒ Idiomas DisponÃ­veis

ğŸ‡¬ğŸ‡§ [InglÃªs](README.md) | ğŸ‡¨ğŸ‡³ [ChinÃªs](README_ZH.md) | ğŸ‡ªğŸ‡¸ [Espanhol](README_ES.md) | ğŸ‡©ğŸ‡ª [AlemÃ£o](README_DE.md) | ğŸ‡«ğŸ‡· [FrancÃªs](README_FR.md) | ğŸ‡®ğŸ‡¹ [Italiano](README_IT.md) | ğŸ‡µğŸ‡¹ [PortuguÃªs](README_PT.md) | ğŸ‡·ğŸ‡º [Russo](README_RU.md) | ğŸ‡°ğŸ‡· [Coreano](README_KO.md) | ğŸ‡¯ğŸ‡µ [JaponÃªs](README_JA.md)

---
# ğŸ§  Whisper Fala-para-Texto (Offline)

Um script Python para **reconhecimento automÃ¡tico de fala a partir de arquivos de Ã¡udio** usando o modelo [Whisper](https://github.com/openai/whisper).  
ApÃ³s o download e configuraÃ§Ã£o, a transcriÃ§Ã£o Ã© realizada **localmente** no seu computador sem enviar dados para nenhum servidor.

- Reconhece fala em mais de 100 idiomas.  
  Para listar os idiomas, execute o script com `--help`.
- O idioma da interface pode ser selecionado com `--ui-lang`.  
  Execute o script sem parÃ¢metros para ver as opÃ§Ãµes disponÃ­veis.
- Modelos suportados: tiny, base, small, medium, large.  
  Quanto â€œmaiorâ€ o modelo, maiores os requisitos de recursos â€” e melhor a precisÃ£o.  
  Se `--model` nÃ£o for especificado, o script seleciona automaticamente um modelo com base na RAM disponÃ­vel.
- ForneÃ§a um arquivo de Ã¡udio com `--file`. Formatos suportados: .wav, .mp3, .m4a, .ogg, etc.  
- Exibe uma prÃ©via curta e salva o texto completo em `output.txt`.

**âš  Importante:**  
Na primeira utilizaÃ§Ã£o de um modelo Whisper selecionado, ele serÃ¡ **baixado da internet** automaticamente.  
O tamanho dos modelos varia de ~150MB (tiny) atÃ© ~3GB (large). Certifique-se de ter uma conexÃ£o estÃ¡vel e espaÃ§o suficiente em disco.

---

## ğŸ–¥ï¸ Requisitos do Sistema
- SO: Windows 10/11, Ubuntu 20.04+, macOS 11+  
- RAM: mÃ­nimo 4GB (16GB recomendados para `large`)  
- EspaÃ§o em disco: ~6GB livres  
- CPU: x86_64 com suporte AVX (recomendado)

ğŸ“¦ ApÃ³s o primeiro download, o modelo funciona totalmente offline.

## âœ… Requisitos
- **Python** 3.10  
- **ffmpeg** (decodificaÃ§Ã£o de Ã¡udio)  
- **git** (clonagem do repositÃ³rio)

---

## âš™ï¸ InstalaÃ§Ã£o

### ğŸªŸ Windows

1. Instale [Python 3.10](https://www.python.org/downloads/)

2. Instale o **Git** (https://git-scm.com/download/win) â€” escolha *â€œGit from the command lineâ€* durante a instalaÃ§Ã£o.

3. Instale o **ffmpeg**: baixe de https://ffmpeg.org/download.html, extraia e adicione `bin/` ao `PATH` (ou coloque `ffmpeg.exe` ao lado do script).

4. Clone o repositÃ³rio:
```bash
git clone https://github.com/avkarcr/audio2text.git
cd audio2text
```

5. Crie e ative um ambiente virtual:
```bash
python -m venv venv
venv\Scriptsctivate
```

6. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

---

### ğŸ§ Linux (Ubuntu/Debian)

1. Instale **Python 3.10+**. No Ubuntu 22.04+ jÃ¡ vem prÃ©-instalado:
```bash
python3 --version
```

2. Instale **git** e **ffmpeg**:
```bash
sudo apt update
sudo apt install git ffmpeg
```

3. Clone o repositÃ³rio:
```bash
git clone https://github.com/avkarcr/audio2text.git
cd audio2text
```

4. Crie e ative um ambiente virtual:
```bash
python3 -m venv venv
source venv/bin/activate
```

5. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

---

## ğŸš€ Uso

1. Coloque o arquivo audio.mp3 na pasta `data/`.  
2. Execute:
```bash
python main.py
```

ğŸ“¦ O modelo e o arquivo serÃ£o selecionados automaticamente.  
Na primeira execuÃ§Ã£o de um modelo, ele serÃ¡ baixado automaticamente.

---

## ğŸ’¡ Exemplos

Executar com o modelo medium em inglÃªs (padrÃ£o) e interface em inglÃªs (padrÃ£o):
```bash
python main.py --quiet --file data/audio.mp3 --model medium
```
Executar com Ã¡udio em coreano e interface em coreano:
```bash
python main.py --quiet --file data/audio.mp3 --model medium --lang ko --ui-lang ko
```
---

## ğŸ“„ SaÃ­da

ğŸ“ PrÃ©via do texto reconhecido, transcriÃ§Ã£o completa salva em `output.txt`.

---

## âš  ObservaÃ§Ãµes
- O modelo large requer 16GB ou mais de RAM.  
- Para Ã¡udios longos, prefira pelo menos o modelo medium (ou divida o arquivo com ffmpeg).

---

## ğŸ“š LicenÃ§a
MIT. Usa componentes do [Whisper](https://github.com/openai/whisper) da OpenAI.
